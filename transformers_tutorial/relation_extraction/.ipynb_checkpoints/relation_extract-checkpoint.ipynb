{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.douban.com/simple\n",
      "Collecting pandas\n",
      "  Downloading https://pypi.doubanio.com/packages/03/ea/98d488a4047b3fd8075b5c1e00469ad42d715e2c1e4fd15fa1ffaef8d635/pandas-1.3.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
      "     |████████████████████████████████| 11.5 MB 42.9 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /root/miniconda3/lib/python3.9/site-packages (from pandas) (2021.3)\n",
      "Collecting numpy>=1.17.3\n",
      "  Downloading https://pypi.doubanio.com/packages/7a/4c/dd00ce768b0f0f7de5c486cbd9f5b922bc3af2f3a5da30121d7f7dc03130/numpy-1.21.2-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.8 MB)\n",
      "     |████████████████████████████████| 15.8 MB 57.8 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /root/miniconda3/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /root/miniconda3/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Installing collected packages: numpy, pandas\n",
      "Successfully installed numpy-1.21.2 pandas-1.3.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.douban.com/simple\n",
      "Collecting matplotlib\n",
      "  Downloading https://pypi.doubanio.com/packages/d0/c6/cca253a56088f330153276d71ffbfccabed9bd59d0c254e6b77aacf9d801/matplotlib-3.4.3-cp39-cp39-manylinux1_x86_64.whl (10.3 MB)\n",
      "     |████████████████████████████████| 10.3 MB 26.1 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /root/miniconda3/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
      "Collecting pillow>=6.2.0\n",
      "  Downloading https://pypi.doubanio.com/packages/e8/23/f55fe5328c78cbe23d019d42570b5b876b721dfe83fbd89c59a04b2acfac/Pillow-8.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "     |████████████████████████████████| 3.0 MB 38.6 MB/s            \n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
      "  Downloading https://pypi.doubanio.com/packages/1f/99/58fe27c8e4a3de823f9fc28ab2c415347efc4139f1c85cac65a008007210/kiwisolver-1.3.2-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "     |████████████████████████████████| 1.6 MB 43.5 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16 in /root/miniconda3/lib/python3.9/site-packages (from matplotlib) (1.21.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /root/miniconda3/lib/python3.9/site-packages (from matplotlib) (2.4.7)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading https://pypi.doubanio.com/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Requirement already satisfied: six in /root/miniconda3/lib/python3.9/site-packages (from cycler>=0.10->matplotlib) (1.16.0)\n",
      "Installing collected packages: pillow, kiwisolver, cycler, matplotlib\n",
      "Successfully installed cycler-0.10.0 kiwisolver-1.3.2 matplotlib-3.4.3 pillow-8.3.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.douban.com/simple\n",
      "Collecting transformers\n",
      "  Downloading https://pypi.doubanio.com/packages/f7/f3/b8b550dccad29c60e681c5f478a48d61c8f47de28fcaed56d97684ca7438/transformers-4.11.3-py3-none-any.whl (2.9 MB)\n",
      "     |████████████████████████████████| 2.9 MB 3.4 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /root/miniconda3/lib/python3.9/site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /root/miniconda3/lib/python3.9/site-packages (from transformers) (4.61.2)\n",
      "Collecting huggingface-hub>=0.0.17\n",
      "  Downloading https://pypi.doubanio.com/packages/96/9a/0686eeeea343df547cbacde15c1bd958eb7a3f5c58291b44a0e2aef1c30c/huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n",
      "     |████████████████████████████████| 56 kB 7.6 MB/s             \n",
      "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading https://pypi.doubanio.com/packages/a8/4f/ca8bc50358c3aaf50f298860a5ce1822e0c0ff97543e32265d1353760555/tokenizers-0.10.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "     |████████████████████████████████| 3.3 MB 40.9 MB/s            \n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading https://pypi.doubanio.com/packages/bd/db/9e43f26de87abc2462e0ef416c450d8ea3791316b0ca3817b7512be4f50e/filelock-3.3.0-py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: requests in /root/miniconda3/lib/python3.9/site-packages (from transformers) (2.25.1)\n",
      "Collecting sacremoses\n",
      "  Downloading https://pypi.doubanio.com/packages/36/bf/15f8df78bce5eee8223553123173f010d426565980e457c559a71ecbecc3/sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
      "     |████████████████████████████████| 895 kB 38.0 MB/s            \n",
      "\u001b[?25hCollecting pyyaml>=5.1\n",
      "  Downloading https://pypi.doubanio.com/packages/12/fc/a4d5a7554e0067677823f7265cb3ae22aed8a238560b5133b58cda252dad/PyYAML-6.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (661 kB)\n",
      "     |████████████████████████████████| 661 kB 15.9 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /root/miniconda3/lib/python3.9/site-packages (from transformers) (1.21.2)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading https://pypi.doubanio.com/packages/b8/a6/e33e1eb262dc58a29e59b75daf5e69e7f3b5907422579a8e8d28a78eb876/regex-2021.10.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (761 kB)\n",
      "     |████████████████████████████████| 761 kB 28.8 MB/s            \n",
      "\u001b[?25hCollecting typing-extensions\n",
      "  Using cached https://pypi.doubanio.com/packages/74/60/18783336cc7fcdd95dae91d73477830aa53f5d3181ae4fe20491d7fc3199/typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /root/miniconda3/lib/python3.9/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /root/miniconda3/lib/python3.9/site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /root/miniconda3/lib/python3.9/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /root/miniconda3/lib/python3.9/site-packages (from requests->transformers) (1.26.6)\n",
      "Collecting joblib\n",
      "  Downloading https://pypi.doubanio.com/packages/3e/d5/0163eb0cfa0b673aa4fe1cd3ea9d8a81ea0f32e50807b0c295871e4aab2e/joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "     |████████████████████████████████| 306 kB 23.4 MB/s            \n",
      "\u001b[?25hCollecting click\n",
      "  Downloading https://pypi.doubanio.com/packages/48/58/c8aa6a8e62cc75f39fee1092c45d6b6ba684122697d7ce7d53f64f98a129/click-8.0.3-py3-none-any.whl (97 kB)\n",
      "     |████████████████████████████████| 97 kB 9.6 MB/s             \n",
      "\u001b[?25hRequirement already satisfied: six in /root/miniconda3/lib/python3.9/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Installing collected packages: typing-extensions, regex, pyyaml, joblib, filelock, click, tokenizers, sacremoses, huggingface-hub, transformers\n",
      "Successfully installed click-8.0.3 filelock-3.3.0 huggingface-hub-0.0.19 joblib-1.1.0 pyyaml-6.0 regex-2021.10.8 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.11.3 typing-extensions-3.10.0.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas matplotlib tensorflow transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_624/2617835704.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# from ast import literal_eval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mBertConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTFBertModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "# from ast import literal_eval\n",
    "from transformers import BertTokenizer,  BertConfig, TFBertModel\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "WARNING:tensorflow:From /tmp/ipykernel_7452/1882028541.py:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "True\n",
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-11 11:07:50.335583: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-10-11 11:07:50.367869: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-10-11 11:07:50.378208: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-10-11 11:07:50.378903: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-10-11 11:07:50.989291: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-10-11 11:07:50.989841: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-10-11 11:07:50.989999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1594] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2021-10-11 11:07:50.990344: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-10-11 11:07:50.990561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /device:GPU:0 with 2761 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "2021-10-11 11:07:50.992012: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-10-11 11:07:50.992488: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-10-11 11:07:50.992908: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(tf.test.is_gpu_available())\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(gpus[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据集整理\n",
    "## 读取数据\n",
    "### 压缩和解压zip文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/招股说明书三元组数据集_云测早期标注\n",
      "./data/招股说明书三元组数据集_云测早期标注.zip\n"
     ]
    }
   ],
   "source": [
    "class ZipHanding:\n",
    "    \"\"\"Decompress the ZIP file or compress the file into a ZIP file\"\"\"\n",
    "    def unzip(self, zipPath, dp=None):  \n",
    "        \"\"\"\n",
    "        Unzip zip file to a folder\n",
    "        \n",
    "        Parameters\n",
    "        ---------\n",
    "        zipPath: Zip file path \n",
    "        dp: Decompression path\n",
    "\n",
    "        Returns\n",
    "        ---------\n",
    "        dir_path: The path of the extracted folder\n",
    "\n",
    "        Raises\n",
    "        ---------\n",
    "        \"\"\"\n",
    "        if dp == None:\n",
    "            ## By default, it is decompressed to the current directory\n",
    "            dp = zipPath.rsplit('.', 1)[0]\n",
    "        if os.path.exists(dp):\n",
    "            shutil.rmtree(dp)        \n",
    "        with zipfile.ZipFile(zipPath, 'r') as f:\n",
    "            for fn in f.namelist():\n",
    "                f.extract(fn, dp)\n",
    "        return dp\n",
    "\n",
    "    def rm_file_folder(self, fp):\n",
    "        '''\n",
    "        remove file or folder\n",
    "        '''\n",
    "        if os.path.exists(fp) and os.path.isfile(fp):\n",
    "            os.remove(fp)\n",
    "        elif os.path.exists(fp) and os.path.isdir(fp):\n",
    "            shutil.rmtree(fp)\n",
    "        else:\n",
    "            raise FileNotFoundError('File not found')\n",
    "\n",
    "    def rename_correctly(self, string):\n",
    "        '''\n",
    "        Rename the garbled characters extracted from the window package\n",
    "        '''\n",
    "        try:\n",
    "            new_string = string.encode('cp437').decode('utf-8')\n",
    "        except:\n",
    "            try:\n",
    "                new_string = string.encode('cp437').decode('gbk')\n",
    "            except:\n",
    "                new_string = string.encode('utf-8').decode('utf-8')\n",
    "        return  new_string\n",
    "        \n",
    "    def rm_special_name_folder(self, dir_path, folder_name='__MACOSX'): \n",
    "        '''\n",
    "        Delete the folder named 'xxxx' if it exists.\n",
    "        The default folder name is __MACOSX.\n",
    "        '''\n",
    "        for root, dirs, files in os.walk(dir_path, topdown=False):\n",
    "            for name in dirs:\n",
    "                if name == folder_name :\n",
    "                    shutil.rmtree(os.path.join(root, name))  \n",
    "\n",
    "    def standard_zip_dir(self, dir_path):\n",
    "        '''\n",
    "        Deal with garbled characters in decompressed files and folder reuse problems\n",
    "        '''\n",
    "        for root, dirs, filenames in os.walk(dir_path):\n",
    "            for fn in filenames:\n",
    "                fp = os.path.join(root, fn)\n",
    "                new_fp = os.path.join(dir_path, self.rename_correctly(fn))\n",
    "                os.rename(fp, new_fp)\n",
    "                \n",
    "        for root, dirs, filenames in os.walk(dir_path):\n",
    "            for folder in dirs:\n",
    "                dp = os.path.join(root, folder)\n",
    "                self.rm_file_folder(dp)\n",
    "                self.rm_special_name_folder(dir_path)   \n",
    "                 \n",
    "    @classmethod\n",
    "    def decompression(cls, zipPath):\n",
    "        dir_path = cls().unzip(zipPath)\n",
    "        cls().standard_zip_dir(dir_path)      \n",
    "        return dir_path\n",
    "\n",
    "    @classmethod\n",
    "    def zip_file(cls, dfp, out_path=None):\n",
    "        \"\"\"\n",
    "        Compresses the specified folder\n",
    "\n",
    "        Parameters\n",
    "        ---------\n",
    "        dfp: Destination folder or file path.\n",
    "        out_path: Save path of the compressed file +xxxx.zip.\n",
    "\n",
    "        Returns\n",
    "        ---------\n",
    "        \"\"\"\n",
    "\n",
    "        if os.path.isdir(dfp):   \n",
    "            if out_path == None:\n",
    "                out_path = dfp + '.zip'\n",
    "            with zipfile.ZipFile(out_path, \"w\", zipfile.ZIP_DEFLATED) as f:\n",
    "                    for root, _, filenames in os.walk(dfp):\n",
    "                        for fn in filenames:\n",
    "                            f.write(filename=os.path.join(root, fn), arcname=fn)\n",
    "        else:\n",
    "            if out_path == None:\n",
    "                out_path = dfp.rsplit('.', 1)[0] + '.zip'\n",
    "            with zipfile.ZipFile(out_path, \"w\", zipfile.ZIP_DEFLATED) as f:\n",
    "                f.write(dfp, dfp.rsplit('/', 1)[1])\n",
    "        print(out_path)\n",
    "\n",
    "\n",
    "zipPath = './data/招股说明书三元组数据集_云测早期标注.zip'\n",
    "dir_path = ZipHanding.decompression(zipPath)\n",
    "print(dir_path)\n",
    "\n",
    "dfp = './data/招股说明书三元组数据集_云测早期标注'\n",
    "ZipHanding.zip_file(dfp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理解压的文件中的乱码和文件夹复用问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取三元组数据json文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_df(path, nrows=False):\n",
    "    '''\n",
    "    Read a TRIplet data JSON file\n",
    "    \n",
    "    Parameters\n",
    "    ---------    \n",
    "    path: file path\n",
    "    nrows: int, optional\n",
    "           The number of lines from the line-delimited jsonfile that has to be read\n",
    "           The default is false, all the rows will be returned.\n",
    "    Returns\n",
    "    ---------  \n",
    "    df: DataFrame\n",
    "    '''\n",
    "    if nrows:\n",
    "        df = pd.read_json(path, nrows=nrows, lines=True)\n",
    "    else:\n",
    "        df = pd.read_json(path, lines=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def merge_json_df(path):\n",
    "    if path.rsplit('.', 1)[1]=='zip':\n",
    "        dir_path = ZipHanding.decompression(path)\n",
    "    else:\n",
    "        dir_path = path\n",
    "    total_df = pd.DataFrame()\n",
    "    for fn in os.listdir(dir_path):\n",
    "        df = json_to_df(os.path.join(dir_path, fn))\n",
    "        df_fn = fn[:fn.rfind('.')]\n",
    "        df.insert(0, 'fn', df_fn)\n",
    "        total_df =  total_df.append(df)\n",
    "    total_df.reset_index(drop=True, inplace=True)\n",
    "    print(f'original data size: {total_df.shape}') #\n",
    "    # print(f'original data sample: {df.sample(5)}\\n')\n",
    "    shutil.rmtree(dir_path)\n",
    "    return total_df  \n",
    "\n",
    "# path1 = './data/三元组数据集_内部标注.zip'\n",
    "# merge_df(path1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从zip或文件夹中读取多个三元组json文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original data size: (837, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fn</th>\n",
       "      <th>text</th>\n",
       "      <th>spo_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>万林股份3</td>\n",
       "      <td>2011年9月29日，公司第一届薪酬与考核委员会第二次会议通过了公司薪酬福利管理制度，具体如...</td>\n",
       "      <td>[{'predicate': '会议召开日期', 'object_type': '公司', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>万林股份3</td>\n",
       "      <td>2012年末、2013年末及2014年末，公司应收新港船务的款项系盈利港务对新港船务的借款。...</td>\n",
       "      <td>[{'predicate': '会议召开日期', 'object_type': '公司', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>万林股份3</td>\n",
       "      <td>2008年3月12日，盈利港务董事会作出决议，将注册资本由500万美元增至3,500万美元，...</td>\n",
       "      <td>[{'predicate': '会议召开日期', 'object_type': '公司', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>万林股份3</td>\n",
       "      <td>1、黄保忠，男，1957年1月出生，硕士。1989年至1993年任上海东申进出口公司副总经理...</td>\n",
       "      <td>[{'predicate': '出生日期', 'object_type': '日期', 's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>万林股份3</td>\n",
       "      <td>2、孙玉峰，男，1961年5月出生，博士，高级经济师。2003年至2011年任日照港股份有限...</td>\n",
       "      <td>[{'predicate': '出生日期', 'object_type': '日期', 's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>长飞光纤</td>\n",
       "      <td>2015年度、2016年度和2017年度，本公司的财务费用分别为12,582.87万元、11...</td>\n",
       "      <td>[{'predicate': '财务费用', 'object_type': '日期', 's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>长飞光纤</td>\n",
       "      <td>本公司2015年度、2016年度及2017年度的资产减值损失分别为3,504.65万元、1,...</td>\n",
       "      <td>[{'predicate': '资产减值损失', 'object_type': '金额', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>长飞光纤</td>\n",
       "      <td>2015年度、2016年度和2017年度，本公司的非经常性损益额分别为6,605.22万元、...</td>\n",
       "      <td>[{'predicate': '非经常性损益', 'object_type': '日期', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>长飞光纤</td>\n",
       "      <td>截至2018年3月31日，公司资产总额达到965,787.67万元，较上年末增长5.35%，...</td>\n",
       "      <td>[{'predicate': '总资产', 'object_type': '金额', 'su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>长飞光纤</td>\n",
       "      <td>2018年1-3月，公司实现营业收入246,526.87万元，较上年同期增长35.24%；净...</td>\n",
       "      <td>[{'predicate': '营业收入', 'object_type': '金额', 's...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>837 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fn                                               text  \\\n",
       "0    万林股份3  2011年9月29日，公司第一届薪酬与考核委员会第二次会议通过了公司薪酬福利管理制度，具体如...   \n",
       "1    万林股份3  2012年末、2013年末及2014年末，公司应收新港船务的款项系盈利港务对新港船务的借款。...   \n",
       "2    万林股份3  2008年3月12日，盈利港务董事会作出决议，将注册资本由500万美元增至3,500万美元，...   \n",
       "3    万林股份3  1、黄保忠，男，1957年1月出生，硕士。1989年至1993年任上海东申进出口公司副总经理...   \n",
       "4    万林股份3  2、孙玉峰，男，1961年5月出生，博士，高级经济师。2003年至2011年任日照港股份有限...   \n",
       "..     ...                                                ...   \n",
       "832   长飞光纤  2015年度、2016年度和2017年度，本公司的财务费用分别为12,582.87万元、11...   \n",
       "833   长飞光纤  本公司2015年度、2016年度及2017年度的资产减值损失分别为3,504.65万元、1,...   \n",
       "834   长飞光纤  2015年度、2016年度和2017年度，本公司的非经常性损益额分别为6,605.22万元、...   \n",
       "835   长飞光纤  截至2018年3月31日，公司资产总额达到965,787.67万元，较上年末增长5.35%，...   \n",
       "836   长飞光纤  2018年1-3月，公司实现营业收入246,526.87万元，较上年同期增长35.24%；净...   \n",
       "\n",
       "                                              spo_list  \n",
       "0    [{'predicate': '会议召开日期', 'object_type': '公司', ...  \n",
       "1    [{'predicate': '会议召开日期', 'object_type': '公司', ...  \n",
       "2    [{'predicate': '会议召开日期', 'object_type': '公司', ...  \n",
       "3    [{'predicate': '出生日期', 'object_type': '日期', 's...  \n",
       "4    [{'predicate': '出生日期', 'object_type': '日期', 's...  \n",
       "..                                                 ...  \n",
       "832  [{'predicate': '财务费用', 'object_type': '日期', 's...  \n",
       "833  [{'predicate': '资产减值损失', 'object_type': '金额', ...  \n",
       "834  [{'predicate': '非经常性损益', 'object_type': '日期', ...  \n",
       "835  [{'predicate': '总资产', 'object_type': '金额', 'su...  \n",
       "836  [{'predicate': '营业收入', 'object_type': '金额', 's...  \n",
       "\n",
       "[837 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def merge_df(path):\n",
    "    if path.rsplit('.', 1)[1]=='zip':\n",
    "        dir_path = ZipHanding.decompression(path)\n",
    "    else:\n",
    "        dir_path = path\n",
    "    total_df = pd.DataFrame()\n",
    "    for fn in os.listdir(dir_path):\n",
    "        df = json_to_df(os.path.join(dir_path, fn))\n",
    "        df_fn = fn[:fn.rfind('.')]\n",
    "        df.insert(0, 'fn', df_fn)\n",
    "        total_df =  total_df.append(df)\n",
    "    total_df.reset_index(drop=True, inplace=True)\n",
    "    print(f'original data size: {total_df.shape}') #\n",
    "    # print(f'original data sample: {df.sample(5)}\\n')\n",
    "    shutil.rmtree(dir_path)\n",
    "    return total_df  \n",
    "\n",
    "path1 = './data/招股说明书三元组数据集_内部标注.zip'\n",
    "merge_df(path1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取关系标签数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_schemads(path_or_df):\n",
    "    if not isinstance(path_or_df, pd.DataFrame):\n",
    "        schemads_path = path_or_df\n",
    "        predicate_data = pd.read_json(schemads_path, lines=True)\n",
    "        id2p = predicate_data['predicate'].drop_duplicates().reset_index(drop=True).to_dict()\n",
    "    else:\n",
    "        df = path_or_df\n",
    "        id2p = df['spo_list'].apply(lambda spo_list: [spo['predicate'] for spo in spo_list])\n",
    "        id2p = id2p.explode().drop_duplicates().reset_index(drop=True).to_dict()\n",
    "    p2id = dict(zip(id2p.values(), id2p.keys()))\n",
    "    print(f'length of p2id :{len(p2id)}')#\n",
    "    print(f'random p2id sample:{random.sample(p2id.items(), 5)}')#\n",
    "    return id2p, p2id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 招股说明书三元组数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original data size: (9500, 3)\n",
      "original data size: (17288, 3)\n",
      "df.shape: (26788, 3)\n",
      "length of p2id :152\n",
      "random p2id sample:[(nan, 25), ('其他成本', 72), ('货币资金', 32), ('股本', 12), ('预付款项余额', 129)]\n"
     ]
    }
   ],
   "source": [
    "path1 = './data/招股说明书三元组数据集_云测早期标注.zip'\n",
    "df1 = merge_df(path1)\n",
    "\n",
    "# path2 = './data/招股说明书三元组数据集_内部标注.zip'\n",
    "# df2 = merge_df(path2)\n",
    "\n",
    "path3 = './data/招股说明书三元组数据集_云测标注.zip'\n",
    "df3= merge_df(path3)\n",
    "\n",
    "df = pd.concat([df1, df3], ignore_index=True)\n",
    "print(f'df.shape: {df.shape}')\n",
    "id2p, p2id = read_schemads(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 清洗数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real data size is 16935\n"
     ]
    }
   ],
   "source": [
    "def clean_spo(spo_list):\n",
    "    for spo in spo_list:\n",
    "        spo['predicate'] = spo['predicate'].lower()\n",
    "        spo['subject'] = spo['subject'].lower()\n",
    "        spo['object'] = spo['object'].lower()\n",
    "    return spo_list\n",
    "\n",
    "def data_clean(df):\n",
    "    df.dropna(how='any', inplace=True)\n",
    "    df = df[df['spo_list'].apply(lambda x: len(x)>0)]\n",
    "    df.drop_duplicates(subset=['text'], inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df['text'] = df['text'].str.lower()\n",
    "    df['spo_list'] = df['spo_list'].apply(clean_spo)\n",
    "    print(f'Real data size is {df.shape[0]}')\n",
    "    return df\n",
    "    \n",
    "df = data_clean(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: (15242, 3)\n",
      "Validation data size: (1693, 3)\n"
     ]
    }
   ],
   "source": [
    "train_size=0.9\n",
    "train_data = df.sample(frac=train_size,random_state=200)\n",
    "dev_data = df.drop(train_data.index)\n",
    "dev_data.reset_index(drop=True, inplace=True)\n",
    "train_data.reset_index(drop=True, inplace=True)\n",
    "print(f'Train data size: {train_data.shape}') #\n",
    "print(f'Validation data size: {dev_data.shape}') \n",
    "\n",
    "train_text = train_data['text'].to_list()\n",
    "train_spo = train_data['spo_list'].to_list()\n",
    "\n",
    "dev_text = dev_data['text'].to_list()\n",
    "dev_spo = dev_data['spo_list'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 标签集分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of p2id category is 153, actual number of labels that meet the requirements is 90\n",
      "Spo count is 43388, number of valid labels is 22895\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spo_list</th>\n",
       "      <th>count</th>\n",
       "      <th>quantity_required</th>\n",
       "      <th>compliance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>主营业务成本-日期-金额</td>\n",
       "      <td>148</td>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>主营业务收入-日期-金额</td>\n",
       "      <td>254</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>任职公司-人物-公司</td>\n",
       "      <td>3227</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>任职公司-人物-日期</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>任职日期-人物-日期</td>\n",
       "      <td>3919</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>预付账款余额-日期-金额</td>\n",
       "      <td>165</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>预收款项-日期-金额</td>\n",
       "      <td>301</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>预收款项余额-日期-金额</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>预收账款余额-日期-金额</td>\n",
       "      <td>194</td>\n",
       "      <td>194</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>预计负债-日期-金额</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         spo_list  count  quantity_required  compliance\n",
       "0    主营业务成本-日期-金额    148                148           0\n",
       "1    主营业务收入-日期-金额    254                200           1\n",
       "2      任职公司-人物-公司   3227                200           1\n",
       "3      任职公司-人物-日期      1                  1           0\n",
       "4      任职日期-人物-日期   3919                200           1\n",
       "..            ...    ...                ...         ...\n",
       "148  预付账款余额-日期-金额    165                165           0\n",
       "149    预收款项-日期-金额    301                200           1\n",
       "150  预收款项余额-日期-金额    166                166           0\n",
       "151  预收账款余额-日期-金额    194                194           0\n",
       "152    预计负债-日期-金额     18                 18           0\n",
       "\n",
       "[153 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def calculate_tag(df, dataset_name, label_range):\n",
    "    '''\n",
    "    label_range: Number range of a single label\n",
    "    '''\n",
    "    start, end = label_range\n",
    "    spo = df['spo_list'].explode().reset_index(drop=True)\n",
    "    spo_group = spo.apply(lambda x: '-'.join([x['predicate'] , x['subject_type'], x['object_type']]))\n",
    "    spo_group_count = spo_group.groupby(spo_group).count().reset_index(name='count')\n",
    "    spo_group_count['quantity_required'] = spo_group_count['count'].apply(lambda x: start if start <= x < end  else x)\n",
    "    spo_group_count['compliance'] = spo_group_count['count'].apply(lambda x: 1 if start <= x < end  else 0)\n",
    "    spo_group_count.to_csv('./data/' + dataset_name + '_spo_group_count.csv', index=False, encoding='utf_8_sig')\n",
    "    spo_group_count.plot(kind='bar', figsize=(25,15))\n",
    "    print(f\"Total number of p2id category is {spo_group_count['count'].shape[0]}, actual number of labels that meet the requirements is {spo_group_count['compliance'].sum()}\")\n",
    "    print(f\"Spo count is {spo_group_count['count'].sum()}, number of valid labels is {spo_group_count['quantity_required'].sum()}\")\n",
    "    return spo_group_count\n",
    "\n",
    "dataset_name = '招股说明书'\n",
    "label_range = [200, float('inf')]\n",
    "spo_group_count = calculate_tag(df, dataset_name, label_range)\n",
    "spo_count = spo_group_count['count'].sum()\n",
    "spo_group_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proceed_data(text_list, spo_list, p2id, tokenizer, MAX_LEN, spo_count):\n",
    "    id_label = {}\n",
    "    ct = len(text_list)\n",
    "    MAX_LEN = MAX_LEN\n",
    "    input_ids = np.zeros((spo_count,MAX_LEN),dtype='int32')\n",
    "    attention_mask = np.zeros((spo_count,MAX_LEN),dtype='int32')\n",
    "    start_tokens = np.zeros((spo_count,MAX_LEN),dtype='int32')\n",
    "    end_tokens = np.zeros((spo_count,MAX_LEN),dtype='int32')\n",
    "    send_s_po = np.zeros((spo_count,2),dtype='int32')\n",
    "    object_start_tokens = np.zeros((spo_count,MAX_LEN,len(p2id)),dtype='int32')\n",
    "    object_end_tokens = np.zeros((spo_count,MAX_LEN,len(p2id)),dtype='int32')\n",
    "    index_vaild = -1\n",
    "    for k in range(ct):\n",
    "        context_k = text_list[k].lower().replace(' ','')\n",
    "        enc_context = tokenizer.encode(context_k,max_length=MAX_LEN,truncation=True)      \n",
    "        start = []\n",
    "        S_index = []\n",
    "        for j in range(len(spo_list[k])):\n",
    "            answers_text_k = spo_list[k][j]['subject'].lower().replace(' ','')\n",
    "            chars = np.zeros((len(context_k)))\n",
    "            index = context_k.find(answers_text_k)\n",
    "            chars[index:index+len(answers_text_k)]=1\n",
    "            offsets = []\n",
    "            idx=0\n",
    "            for t in enc_context[1:]:\n",
    "                w = tokenizer.decode([t])\n",
    "                if '#' in w and len(w)>1:\n",
    "                    w = w.replace('#','')\n",
    "                if w == '[UNK]':\n",
    "                    w = '。'\n",
    "                offsets.append((idx,idx+len(w)))\n",
    "                idx += len(w)\n",
    "            toks = []\n",
    "            for i,(a,b) in enumerate(offsets):\n",
    "                sm = np.sum(chars[a:b])\n",
    "                if sm>0: \n",
    "                    toks.append(i) \n",
    "            if len(toks)>0:\n",
    "                S_start = toks[0]+1\n",
    "                S_end = toks[-1]+1\n",
    "                if (S_start,S_end) not in start:\n",
    "                    index_vaild += 1\n",
    "                    start.append((S_start,S_end))\n",
    "                    input_ids[index_vaild,:len(enc_context)] = enc_context\n",
    "                    attention_mask[index_vaild,:len(enc_context)] = 1\n",
    "                    start_tokens[index_vaild,S_start] = 1\n",
    "                    end_tokens[index_vaild,S_end] = 1\n",
    "                    send_s_po[index_vaild,0] = S_start\n",
    "                    send_s_po[index_vaild,1] = S_end\n",
    "                    S_index.append([j,index_vaild])\n",
    "                else:\n",
    "                    S_index.append([j,index_vaild])\n",
    "        if len(S_index) > 0:\n",
    "            for index_ in range(len(S_index)):\n",
    "                #随机选取object的首位，如果选取错误，则作为负样本\n",
    "                object_text_k = spo_list[k][S_index[index_][0]]['object'].lower().replace(' ','')\n",
    "                predicate = spo_list[k][S_index[index_][0]]['predicate']\n",
    "                p_id = p2id[predicate]\n",
    "                chars = np.zeros((len(context_k)))\n",
    "                index = context_k.find(object_text_k)\n",
    "                chars[index:index+len(object_text_k)]=1\n",
    "                offsets = [] \n",
    "                idx = 0\n",
    "                for t in enc_context[1:]:\n",
    "                    w = tokenizer.decode([t])\n",
    "                    if '#' in w and len(w)>1:\n",
    "                        w = w.replace('#','')\n",
    "                    if w == '[UNK]':\n",
    "                        w = '。'\n",
    "                    offsets.append((idx,idx+len(w)))\n",
    "                    idx += len(w)\n",
    "                toks = []\n",
    "                for i,(a,b) in enumerate(offsets):\n",
    "                    sm = np.sum(chars[a:b])\n",
    "                    if sm>0: \n",
    "                        toks.append(i) \n",
    "                if len(toks)>0:\n",
    "                    id_label[p_id] = predicate\n",
    "                    P_start = toks[0]+1\n",
    "                    P_end = toks[-1]+1\n",
    "                    object_start_tokens[S_index[index_][1]][P_start,p_id] = 1\n",
    "                    object_end_tokens[S_index[index_][1]][P_end,p_id] = 1\n",
    "    return input_ids[:index_vaild], attention_mask[:index_vaild], start_tokens[:index_vaild], end_tokens[:index_vaild], send_s_po[:index_vaild], \\\n",
    "           object_start_tokens[:index_vaild], object_end_tokens[:index_vaild], id_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start tokens shape: (26047, 256)\n",
      "CPU times: user 4min 15s, sys: 1.68 s, total: 4min 16s\n",
      "Wall time: 4min 17s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-11 11:12:23.712300: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-10-11 11:12:23.712862: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-10-11 11:12:23.713334: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-10-11 11:12:23.714330: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-10-11 11:12:23.714554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1594] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2021-10-11 11:12:23.715008: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-10-11 11:12:23.715204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2761 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "MAX_LEN = 256  \n",
    "pretrained_path = '../model_dirs/chinese-bert-wwm-ext'  \n",
    "tokenizer = BertTokenizer.from_pretrained(pretrained_path)\n",
    "input_ids, attention_mask, start_tokens, end_tokens, send_s_po, object_start_tokens, object_end_tokens, id_label \\\n",
    "= proceed_data(train_text, train_spo, p2id, tokenizer, MAX_LEN, spo_count)\n",
    "\n",
    "print(f'start tokens shape: {start_tokens.shape}')\n",
    "\n",
    "val_inputs = tokenizer(dev_text, max_length=MAX_LEN, padding='max_length', truncation=True, return_tensors='tf') \n",
    "val_input_ids, val_attention_mask = val_inputs['input_ids'], val_inputs['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_loss(true,pred):\n",
    "    true = tf.cast(true,tf.float32)\n",
    "    loss = K.sum(K.binary_crossentropy(true, pred))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormalization(tf.keras.layers.Layer):\n",
    "    \"\"\"(Conditional) Layer Normalization\n",
    "    hidden_*系列参数仅为有条件输入时(conditional=True)使用\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        center=True,\n",
    "        scale=True,\n",
    "        epsilon=None,\n",
    "        conditional=False,\n",
    "        hidden_units=None,\n",
    "        hidden_activation='linear',\n",
    "        hidden_initializer='glorot_uniform',\n",
    "        **kwargs):\n",
    "        super(LayerNormalization, self).__init__(**kwargs)\n",
    "        self.center = center\n",
    "        self.scale = scale\n",
    "        self.conditional = conditional\n",
    "        self.hidden_units = hidden_units\n",
    "        self.hidden_activation = tf.keras.activations.get(hidden_activation)\n",
    "        self.hidden_initializer = tf.keras.initializers.get(hidden_initializer)\n",
    "        self.epsilon = epsilon or 1e-12\n",
    "        \n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        if self.conditional:\n",
    "            masks = mask if mask is not None else []\n",
    "            masks = [m[None] for m in masks if m is not None]\n",
    "            if len(masks) == 0:\n",
    "                return None\n",
    "            else:\n",
    "                return K.all(K.concatenate(masks, axis=0), axis=0)\n",
    "        else:\n",
    "            return mask\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        super(LayerNormalization, self).build(input_shape)\n",
    "        if self.conditional:\n",
    "            shape = (input_shape[0][-1],)\n",
    "        else:\n",
    "            shape = (input_shape[-1],)\n",
    "        if self.center:\n",
    "            self.beta = self.add_weight(\n",
    "                shape=shape, initializer='zeros', name='beta')\n",
    "        if self.scale:\n",
    "            self.gamma = self.add_weight(\n",
    "                shape=shape, initializer='ones', name='gamma')\n",
    "        if self.conditional:\n",
    "            if self.hidden_units is not None:\n",
    "                self.hidden_dense = tf.keras.layers.Dense(\n",
    "                    units=self.hidden_units,\n",
    "                    activation=self.hidden_activation,\n",
    "                    use_bias=False,\n",
    "                    kernel_initializer=self.hidden_initializer)\n",
    "            if self.center:\n",
    "                self.beta_dense = tf.keras.layers.Dense(\n",
    "                    units=shape[0], use_bias=False, kernel_initializer='zeros')\n",
    "            if self.scale:\n",
    "                self.gamma_dense = tf.keras.layers.Dense(\n",
    "                    units=shape[0], use_bias=False, kernel_initializer='zeros')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"如果是条件Layer Norm，则默认以list为输入，第二个是condition\n",
    "        \"\"\"\n",
    "        if self.conditional:\n",
    "            inputs, cond = inputs\n",
    "            if self.hidden_units is not None:\n",
    "                cond = self.hidden_dense(cond)\n",
    "            for _ in range(K.ndim(inputs) - K.ndim(cond)):\n",
    "                cond = K.expand_dims(cond, 1)\n",
    "            if self.center:\n",
    "                beta = self.beta_dense(cond) + self.beta\n",
    "            if self.scale:\n",
    "                gamma = self.gamma_dense(cond) + self.gamma\n",
    "        else:\n",
    "            if self.center:\n",
    "                beta = self.beta\n",
    "            if self.scale:\n",
    "                gamma = self.gamma\n",
    "        outputs = inputs\n",
    "        if self.center:\n",
    "            mean = K.mean(outputs, axis=-1, keepdims=True)\n",
    "            outputs = outputs - mean\n",
    "        if self.scale:\n",
    "            variance = K.mean(K.square(outputs), axis=-1, keepdims=True)\n",
    "            std = K.sqrt(variance + self.epsilon)\n",
    "            outputs = outputs / std\n",
    "            outputs = outputs * gamma\n",
    "        if self.center:\n",
    "            outputs = outputs + beta\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_subject(inputs):\n",
    "    \"\"\"根据subject_ids从output中取出subject的向量表征\n",
    "    \"\"\"\n",
    "    output, subject_ids = inputs\n",
    "    start = tf.gather(output,subject_ids[:,0],axis=1,batch_dims=1)\n",
    "    end = tf.gather(output,subject_ids[:,1],axis=1,batch_dims=1)\n",
    "    subject = tf.keras.layers.Concatenate(axis=1)([start, end])\n",
    "    return subject\n",
    "'''\n",
    "   output.shape = \n",
    "   (None,128,768)\n",
    "   subjudec_ids.shape = (None,2)\n",
    "   start.shape = (None,None,768)\n",
    "   subject.shape = (None,None,1536)\n",
    "   subject[:,0].shape = (None,1536)\n",
    "   这一部分给出各个变量的shape应该一目了然\n",
    "'''\n",
    "   \n",
    "def build_model_2(pretrained_path, MAX_LEN, p2id):\n",
    "    ids = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
    "    att = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
    "    s_po_index =  tf.keras.layers.Input((2,), dtype=tf.int32)\n",
    "    \n",
    "    bert_model = TFBertModel.from_pretrained(pretrained_path, output_hidden_states=True)\n",
    "    outputs = bert_model(ids, attention_mask=att)\n",
    "    x, _, hidden_states  = outputs[:3]\n",
    "    layer_1 = hidden_states[-1]\n",
    "    start_logits = tf.keras.layers.Dense(1,activation = 'sigmoid')(layer_1)\n",
    "    start_logits = tf.keras.layers.Lambda(lambda x: x**2)(start_logits)\n",
    "    \n",
    "    end_logits = tf.keras.layers.Dense(1,activation = 'sigmoid')(layer_1)\n",
    "    end_logits = tf.keras.layers.Lambda(lambda x: x**2)(end_logits)\n",
    "    \n",
    "    subject_1 = extract_subject([layer_1,s_po_index])\n",
    "    Normalization_1 = LayerNormalization(conditional=True)([layer_1, subject_1])\n",
    "    \n",
    "    op_out_put_start = tf.keras.layers.Dense(len(p2id),activation = 'sigmoid')(Normalization_1)\n",
    "    op_out_put_start = tf.keras.layers.Lambda(lambda x: x**4)(op_out_put_start)\n",
    "    \n",
    "    op_out_put_end = tf.keras.layers.Dense(len(p2id),activation = 'sigmoid')(Normalization_1)\n",
    "    op_out_put_end = tf.keras.layers.Lambda(lambda x: x**4)(op_out_put_end)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=[ids, att, s_po_index], outputs=[start_logits, end_logits, op_out_put_start, op_out_put_end])\n",
    "    model_2 = tf.keras.models.Model(inputs=[ids, att], outputs=[start_logits,end_logits])\n",
    "    model_3 = tf.keras.models.Model(inputs=[ids, att, s_po_index], outputs=[op_out_put_start, op_out_put_end])\n",
    "    return model, model_2, model_3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rematch_text_word(tokenizer,text,enc_context,enc_start,enc_end):\n",
    "    span = [a.span()[0] for a in re.finditer(' ', text)]\n",
    "    decode_list = [tokenizer.decode([i]) for i in enc_context][1:]\n",
    "    start = 0\n",
    "    end = 0\n",
    "    len_start = 0\n",
    "    for i in range(len(decode_list)):\n",
    "        if i ==  enc_start - 1:\n",
    "            start = len_start\n",
    "        j = decode_list[i]\n",
    "        if '#' in j and len(j)>1:\n",
    "            j = j.replace('#','')\n",
    "        if j == '[UNK]':\n",
    "            j = '。'\n",
    "        len_start += len(j)\n",
    "        if i == enc_end - 1:\n",
    "            end = len_start\n",
    "            break\n",
    "    for span_index in span:\n",
    "        if start >= span_index:\n",
    "            start += 1\n",
    "            end += 1\n",
    "        if end > span_index and span_index>start:\n",
    "            end += 1\n",
    "    return text[start:end]\n",
    "\n",
    "\n",
    "class Metrics(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, model_2, model_3, id2tag, va_text_list, va_spo_list, va_input_ids, va_attention_mask, tokenizer, folder_path):\n",
    "        super(Metrics, self).__init__()\n",
    "        self.model_2 = model_2\n",
    "        self.model_3 = model_3\n",
    "        self.id2tag = id2tag\n",
    "        self.va_input_ids = va_input_ids\n",
    "        self.va_attention_mask = va_attention_mask\n",
    "        self.va_spo_list = va_spo_list\n",
    "        self.va_text_list = va_text_list\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.val_f1s = []\n",
    "        self.best_val_f1 = 0\n",
    "    \n",
    "    def get_same_element_index(self,ob_list):\n",
    "        return [i for (i, v) in enumerate(ob_list) if v == 1]\n",
    "    \n",
    "    def evaluate_data(self):\n",
    "        Y1 = self.model_2.predict([self.va_input_ids,self.va_attention_mask])\n",
    "        question=[]\n",
    "        answer=[]\n",
    "        for m in range(len(Y1[0])):\n",
    "            for z in self.va_spo_list[m]:\n",
    "                question.append((z['subject'],z['predicate'],z['object']))\n",
    "            start = np.where(Y1[0][m]>0.5)[0]\n",
    "            end = np.where(Y1[1][m]>0.5)[0]\n",
    "            subjects = []\n",
    "            for i in start:\n",
    "                j = end[end >= i]\n",
    "                if len(j) > 0:\n",
    "                    j = j[0]\n",
    "                    subjects.append((i, j))\n",
    "            if subjects:\n",
    "                token_ids_2 = np.repeat([self.va_input_ids[m]], len(subjects), 0)\n",
    "                attention_mask_2 = np.repeat([self.va_attention_mask[m]], len(subjects), 0)\n",
    "                subjects = np.array(subjects)\n",
    "                object_preds_start,object_preds_end = self.model_3.predict([token_ids_2, attention_mask_2, subjects])\n",
    "                for subject,object_start,object_end in zip(subjects,object_preds_start,object_preds_end):\n",
    "                    sub = rematch_text_word(self.tokenizer,self.va_text_list[m],self.va_input_ids[m],subject[0],subject[1])\n",
    "                    start = np.argwhere(object_start > 0.5)\n",
    "                    end = np.argwhere(object_end > 0.5)\n",
    "                    for _start, predicate1 in start:\n",
    "                        for _end, predicate2 in end:\n",
    "                            if _start <= _end and predicate1 == predicate2:\n",
    "                                ans = rematch_text_word(self.tokenizer,self.va_text_list[m],self.va_input_ids[m],_start,_end)\n",
    "                                answer.append((sub,self.id2tag[predicate1],ans))\n",
    "                                break\n",
    "        Q = set(question)\n",
    "        S = set(answer)\n",
    "        f1 = 2*len(Q&S)/(len(Q)+len(S))\n",
    "        return f1\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        _val_f1 = self.evaluate_data()\n",
    "        self.val_f1s.append(_val_f1)\n",
    "        logs['val_f1'] = _val_f1\n",
    "        if _val_f1 > self.best_val_f1:\n",
    "            self.model.save_weights(os.path.join(folder_path, f'f1={round(_val_f1, 4)}_model.h5'))\n",
    "            self.best_val_f1 = _val_f1\n",
    "            print(\"best f1: {} \\n\".format(self.best_val_f1))\n",
    "        else:\n",
    "            print(\"val f1: {}, but not the best f1 \\n\".format(_val_f1))\n",
    "        return      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '../model_dirs/fine_tune_relation_extraction'\n",
    "epochs = 5\n",
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertModel.\n",
      "\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at ../model_dirs/chinese-bert-wwm-ext.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
      "2021-10-11 11:12:33.543159: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 4054163456 exceeds 10% of free system memory.\n",
      "2021-10-11 11:12:34.984881: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 4054163456 exceeds 10% of free system memory.\n",
      "2021-10-11 11:12:36.583958: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "13024/13024 [==============================] - 56245s 4s/step - loss: 69.1961 - lambda_loss: 5.5095 - lambda_1_loss: 5.7211 - lambda_2_loss: 28.5840 - lambda_3_loss: 29.3812\n",
      "best f1: 0.34947800787266814 \n",
      "\n",
      "Epoch 2/5\n",
      " 7213/13024 [===============>..............] - ETA: 44:01 - loss: 22.9319 - lambda_loss: 3.7816 - lambda_1_loss: 3.9689 - lambda_2_loss: 7.5024 - lambda_3_loss: 7.6789"
     ]
    }
   ],
   "source": [
    "# config = BertConfig.from_json_file('../model_dirs/chinese-bert-wwm-ext/config.json')\n",
    "# TFBertModel.from_pretrained(pretrained_path, config=config)\n",
    "K.clear_session()\n",
    "model,model_2,model_3 = build_model_2(pretrained_path,  MAX_LEN, p2id)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "model.compile(loss={'lambda': new_loss,\n",
    "                'lambda_1': new_loss,\n",
    "                'lambda_2': new_loss,\n",
    "                'lambda_3': new_loss},optimizer=optimizer)\n",
    "model.fit([input_ids, attention_mask, send_s_po], [start_tokens, end_tokens, object_start_tokens, object_end_tokens], \\\n",
    "        epochs=epochs, batch_size=batch_size, callbacks=[Metrics(model_2, model_3 ,id2p, dev_text, dev_spo, val_input_ids, val_attention_mask, tokenizer, folder_path)])\n",
    "\n",
    "# h5_path = '../model_dirs/fine_tune_relation_extraction/tf_model.h5'\n",
    "# model.save_weights(h5_path)\n",
    "# checkpoint_path = '../model_dirs/fine_tune_relation_extraction/checkpoints/my_checkpoint'\n",
    "# model.save_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_path = '../model_dirs/chinese-bert-wwm-ext'\n",
    "checkpoint_path = '../model_dirs/fine_tune_relation_extraction/checkpoints/my_checkpoint'\n",
    "h5_path = '../model_dirs/fine_tune_relation_extraction/tf_model.h5'\n",
    "model,model_2,model_3 = build_model_2(pretrained_path, MAX_LEN, p2id)\n",
    "model.load_weights(h5_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "x1 = [input_ids[[idx]], attention_mask[[idx]]]\n",
    "sub_start_tokens, sub_end_tokens = model_2.predict(x1)\n",
    "train_spo[idx], p2id[train_spo[idx][0]['predicate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_start_idx = int(np.argwhere(sub_start_tokens[0,:,0] > 0.5)[0])\n",
    "sub_end_idx = int(np.argwhere(sub_end_tokens[0,:,0] > 0.5)[0])\n",
    "sub_text = tokenizer.decode(input_ids[idx][sub_start_idx:sub_end_idx+1]).replace(' ','')\n",
    "sub_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = [input_ids[[idx]], attention_mask[[idx]], send_s_po[[idx]]]\n",
    "obj_start_tokens, obj_end_tokens = model_3.predict(x2)\n",
    "obj_start_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_start_idx = np.argwhere(obj_start_tokens[0] > 0.5)\n",
    "obj_end_idx = np.argwhere(obj_end_tokens[0] > 0.5)\n",
    "for _start, predicate1 in obj_start_idx:\n",
    "    for _end, predicate2 in obj_end_idx:\n",
    "        if _start <= _end and predicate1 == predicate2:\n",
    "            print(_start, _end, predicate1)\n",
    "            obj_text = tokenizer.decode(input_ids[idx][_start:_end+1]).replace(' ','')\n",
    "            print(obj_text, id2p[predicate1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "pid = os.getpid()\n",
    "!kill -9 $pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad8a153ad2dd132b04ef6e3413d315d7d81f68b3d06a421cf8661d6db53905e3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
