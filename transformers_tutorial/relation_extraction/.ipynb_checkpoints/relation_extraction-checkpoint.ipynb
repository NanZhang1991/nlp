{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import random\r\n",
    "from random import choice\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from transformers import BertTokenizer,  BertConfig, TFBertModel\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow.keras import backend as K\r\n",
    "import os\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 数据集整理\r\n",
    "## 读取数据"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def json_to_df(path, nrows=False):\r\n",
    "    if nrows:\r\n",
    "        df = pd.read_json(path, nrows=nrows, lines=True)\r\n",
    "    else:\r\n",
    "        df = pd.read_json(path, lines=True)\r\n",
    "    df = df[['text', 'spo_list']]\r\n",
    "    return df\r\n",
    "\r\n",
    "def merge_df(dir_path):\r\n",
    "    total_df = pd.DataFrame()\r\n",
    "    for fn in os.listdir(dir_path):\r\n",
    "        df = json_to_df(os.path.join(dir_path, fn))\r\n",
    "        df_fn = fn[:fn.rfind('.')]\r\n",
    "        df.insert(0, 'fn', df_fn)\r\n",
    "        total_df =  total_df.append(df)\r\n",
    "    total_df.reset_index(drop=True, inplace=True)\r\n",
    "    print(f'data size: {total_df.shape}') #\r\n",
    "    print(f'data sample: {df.sample(5)}')\r\n",
    "    return total_df   \r\n",
    "\r\n",
    "def read_schemads(path_or_df):\r\n",
    "    if not isinstance(path_or_df, pd.DataFrame):\r\n",
    "        print(1)\r\n",
    "        schemads_path = path_or_df\r\n",
    "        predicate_data = pd.read_json(schemads_path, lines=True)\r\n",
    "        id2p = predicate_data['predicate'].drop_duplicates().reset_index(drop=True).to_dict()\r\n",
    "    else:\r\n",
    "        df = path_or_df\r\n",
    "        id2p = df['spo_list'].apply(lambda spo_list: [spo['predicate'] for spo in spo_list])\r\n",
    "        id2p = id2p.explode().drop_duplicates().reset_index(drop=True).to_dict()\r\n",
    "    p2id = dict(zip(id2p.values(), id2p.keys()))\r\n",
    "    print(f'length of p2id :{len(p2id)}')#\r\n",
    "    print(f'random p2id sample:{random.sample(p2id.items(), 5)}')#\r\n",
    "    return id2p, p2id"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# %%time\r\n",
    "# # 百度三元组关系数据集\r\n",
    "# train_path ='../data/百度关系抽取数据集/train_data.json'\r\n",
    "# train_data = json_to_df(train_path, nrows=10000)\r\n",
    "# print(f'Train data size: {train_data.shape}') #\r\n",
    "\r\n",
    "# dev_path = '../data/百度关系抽取数据集/dev_data.json'\r\n",
    "# dev_data = json_to_df(dev_path, nrows=5000)\r\n",
    "# print(f'Validation data size: {dev_data.shape}') \r\n",
    "\r\n",
    "# schemads_path = '../data/百度关系抽取数据集/all_50_schemas'\r\n",
    "# id2p, p2id = read_schemads(schemads_path)#"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "## 招股说明书三元组数据集\r\n",
    "dir_path = '../data/招股说明书三元组数据集'\r\n",
    "df = merge_df(dir_path)\r\n",
    "id2p, p2id = read_schemads(df)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "data size: (10698, 3)\n",
      "data sample:                    fn                                               text  \\\n",
      "113  阿科力首次公开发行股票招股说明书  2015年6月5日，公司召开2015年第一次临时股东大会，选举丁玉强、冯凯燕、单世文担任第一...   \n",
      "57   阿科力首次公开发行股票招股说明书  崔小丽，女，1966年3月出生，中国国籍，无境外永久居留权，本科学历。身份证号码为32062...   \n",
      "100  阿科力首次公开发行股票招股说明书  2013年1月，朱学军以1.45元/股将其持有公司的80万元和30万元股权分别转让给诚鼎创投...   \n",
      "36   阿科力首次公开发行股票招股说明书  2015年，财务费用较上年下降158.43万元，主要原因是：由于公司业绩持续快速增长，并采用...   \n",
      "49   阿科力首次公开发行股票招股说明书  2008年7月1日，经公司股东会决议批准，将原注册资本1,000万元增资至6,000万元，其...   \n",
      "\n",
      "                                              spo_list  \n",
      "113  [{'predicate': '任职日期', 'object_type': '日期', 's...  \n",
      "57   [{'predicate': '出生日期', 'object_type': '日期', 's...  \n",
      "100  [{'predicate': '转让日期', 'object_type': '日期', 's...  \n",
      "36   [{'predicate': '财务费用', 'object_type': '金额', 's...  \n",
      "49   [{'predicate': '注册资本', 'object_type': '金额', 's...  \n",
      "length of p2id :116\n",
      "random p2id sample:[('应付职工薪酬', 62), ('存货周转率', 76), ('应收合计', 69), ('长期待摊费用', 102), ('固定资产', 84)]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 清洗数据"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def clean_spo(spo_list):\r\n",
    "    for spo in spo_list:\r\n",
    "        spo['predicate'] = spo['predicate'].lower()\r\n",
    "        spo['subject'] = spo['subject'].lower()\r\n",
    "        spo['object'] = spo['object'].lower()\r\n",
    "    return spo_list\r\n",
    "\r\n",
    "def data_clean(df):\r\n",
    "    df.dropna(how='any', inplace=True)\r\n",
    "    df = df[df['spo_list'].apply(lambda x: len(x)>0)]\r\n",
    "    df.drop_duplicates(subset=['text'], inplace=True)\r\n",
    "    df.reset_index(drop=True, inplace=True)\r\n",
    "    df['text'] = df['text'].str.lower()\r\n",
    "    df['spo_list'] = df['spo_list'].apply(clean_spo)\r\n",
    "    print(f'Real data size is {df.shape[0]}')\r\n",
    "    return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "df = data_clean(df)\r\n",
    "# train_data = data_clean(train_data)\r\n",
    "# dev_data = data_clean(dev_data)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Real data size is 8436\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ipykernel_launcher:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "ipykernel_launcher:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "ipykernel_launcher:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 划分数据集"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "train_size=0.9\r\n",
    "\r\n",
    "train_data = df.sample(frac=train_size,random_state=200)\r\n",
    "dev_data = df.drop(train_data.index)\r\n",
    "dev_data.reset_index(drop=True, inplace=True)\r\n",
    "train_data.reset_index(drop=True, inplace=True)\r\n",
    "print(f'Train data size: {train_data.shape}') #\r\n",
    "print(f'Validation data size: {dev_data.shape}') \r\n",
    "\r\n",
    "spo_single_count = df['spo_list'].apply(lambda x: len(x))\r\n",
    "spo_count = spo_single_count.sum()\r\n",
    "print('spo_count', spo_count)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train data size: (7592, 3)\n",
      "Validation data size: (844, 3)\n",
      "spo_count 24451\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "train_text = train_data['text'].to_list()\r\n",
    "train_spo = train_data['spo_list'].to_list()\r\n",
    "                                                \r\n",
    "dev_text = dev_data['text'].to_list()\r\n",
    "dev_spo = dev_data['spo_list'].to_list()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "spo_count 24451\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 标签集分布情况"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "dataset_name = '招股说明书'\r\n",
    "spo = df['spo_list'].explode().reset_index(drop=True)\r\n",
    "spo_group = spo.apply(lambda x: '-'.join([x['predicate'] , x['subject_type'], x['object_type']]))\r\n",
    "spo_group_count = spo_group.groupby(spo_group).count().reset_index(name='count')\r\n",
    "spo_group_count['compliance '] = spo_group_count['count'].apply(lambda x: 1 if 200<x<500 else 0)\r\n",
    "print(spo_group_count.head())\r\n",
    "spo_group_count.to_csv('../data/' + dataset_name + '_spo_group_count.csv', index=False, encoding='utf_8_sig')\r\n",
    "spo_group_count.plot(kind='bar', figsize=(30,15))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "       spo_list  count  compliance \n",
      "0  主营业务成本-日期-金额     33            0\n",
      "1  主营业务收入-日期-金额    233            1\n",
      "2    任职公司-人物-公司   3243            0\n",
      "3    任职公司-人物-日期      1            0\n",
      "4    任职日期-人物-日期   3160            0\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 2160x1080 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 数据集处理"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "def find_head_idx(pattern, sequence):\r\n",
    "    \"\"\"从sequence中寻找子串pattern\r\n",
    "    如果找到，返回第一个下标；否则返回-1。\r\n",
    "    \"\"\"\r\n",
    "    n = len(pattern)\r\n",
    "    for i in range(len(sequence)):\r\n",
    "        if sequence[i:i + n] == pattern:\r\n",
    "            return i\r\n",
    "    return -1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "def data_process(df, p2id, tokenizer, max_length):\r\n",
    "    long_text_count = 0\r\n",
    "    total_token_ids, total_token_type_ids, total_attention_mask = [], [], []\r\n",
    "    total_subject_labels, total_subject_ids, total_object_labels = [], [], []\r\n",
    "    for idx in df.index:\r\n",
    "        row = df.loc[idx]\r\n",
    "        inputs = tokenizer(row['text'], max_length=max_length, padding='max_length', truncation=True)\r\n",
    "        token_ids, token_type_ids, attention_mask = inputs['input_ids'], inputs['token_type_ids'], inputs['attention_mask']\r\n",
    "        # 实体关系token id 位置字典\r\n",
    "        s2op_map = {}\r\n",
    "        for sop_n, spo in enumerate(row['spo_list']):\r\n",
    "            sub_ids = tokenizer.encode(spo['subject'])[1:-1]\r\n",
    "            p_id = p2id[spo['predicate']]\r\n",
    "            obj_ids = tokenizer.encode(spo['object'])[1:-1]\r\n",
    "            # 查找subject 和 object对应的token id 起始索引\r\n",
    "            sub_head_idx = find_head_idx(sub_ids, inputs['input_ids'])\r\n",
    "            obj_head_idx = find_head_idx(obj_ids, inputs['input_ids'])\r\n",
    "            if sub_head_idx != -1 and obj_head_idx != -1:\r\n",
    "                # 获取subject 起始位置的索引和结束位置索引的元组\r\n",
    "                sub = (sub_head_idx, sub_head_idx + len(sub_ids) - 1)\r\n",
    "                # 获取object 起始位置的索引和结束位置索引元组以及与关系标签id的元组对\r\n",
    "                obj = (obj_head_idx, obj_head_idx + len(obj_ids) - 1, p_id)\r\n",
    "                # print('---- sub -----', sub)#    \r\n",
    "                if sub not in s2op_map:\r\n",
    "                    s2op_map[sub] = []\r\n",
    "                s2op_map[sub].append(obj)\r\n",
    "                # print('-----------', s2op_map)#                \r\n",
    "                {(22,23):[(28, 29, 7), (25, 26, 8)]}  \r\n",
    "            else:\r\n",
    "                long_text_count +=1\r\n",
    "                # print('--idx--', idx, '--text--', row['text'])\r\n",
    "                # print('--sop_n--', sop_n, '--spo--', spo, '\\n')\r\n",
    "\r\n",
    "\r\n",
    "        if s2op_map:\r\n",
    "        # subject标签\r\n",
    "            subject_labels = np.zeros((max_length, 2))\r\n",
    "            for s in s2op_map:\r\n",
    "                #sub_head\r\n",
    "                subject_labels[s[0], 0] = 1\r\n",
    "                #sub_tail\r\n",
    "                subject_labels[s[1], 1] = 1\r\n",
    "            # 随机选一个subject\r\n",
    "            sub_head, sub_tail = choice(list(s2op_map.keys()))\r\n",
    "            subject_ids = (sub_head, sub_tail)\r\n",
    "            # sub_head, sub_tail = np.array(list(s2op_map.keys())).T\r\n",
    "            # sub_head = np.random.choice(sub_head)\r\n",
    "            # sub_tail = np.random.choice(sub_tail[sub_tail >= sub_head])\r\n",
    "            # 对应的object标签\r\n",
    "            object_labels = np.zeros((len(token_ids), len(p2id), 2))\r\n",
    "            for op in s2op_map.get((sub_head, sub_tail), []):\r\n",
    "                # print(op)\r\n",
    "                # obj_head\r\n",
    "                object_labels[op[0], op[2], 0] = 1\r\n",
    "                # obj_tail\r\n",
    "                object_labels[op[1], op[2], 1] = 1\r\n",
    "\r\n",
    "            # 所有数据汇总\r\n",
    "            total_token_ids.append(token_ids)\r\n",
    "            total_token_type_ids.append(token_type_ids)\r\n",
    "            total_attention_mask.append(attention_mask)\r\n",
    "            total_subject_labels.append(subject_labels)\r\n",
    "            total_subject_ids.append(subject_ids)\r\n",
    "            total_object_labels.append(object_labels)  \r\n",
    "    print('long_text_count', long_text_count)                      \r\n",
    "    return total_token_ids, total_token_type_ids, total_attention_mask, \\\r\n",
    "           total_subject_labels, total_subject_ids, total_object_labels"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# input_demo = data_process(train_data[3:4], p2id, tokenizer, max_length)\r\n",
    "# print(np.array(input_demo[5]).shape)\r\n",
    "# print(train_spo[3])\r\n",
    "# print(np.array(input_demo[5])[0, 25, 14, 0], np.array(input_demo[5])[0, 27, 14, 1])\r\n",
    "# print(np.array(input_demo[5])[0, 14, 17, 0], np.array(input_demo[5])[0, 14, 17, 1])\r\n",
    "# # tokenizer.decode(train_input_ids[3][op_s:op_e+1])\r\n",
    "# print(train_spo[3])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "%%time\r\n",
    "model_path = '../model_dirs/bert-base-chinese'  \r\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\r\n",
    "max_length = 512\r\n",
    "train_input_ids, train_token_type_ids, train_attention_mask, train_subject_labels, train_subject_ids, train_object_labels  = data_process(train_data, p2id, tokenizer, max_length)\r\n",
    "print(train_subject_ids[:2])\r\n",
    "print(np.array(train_subject_labels).shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "long_text_count 181\n",
      "[(48, 49), (1, 3)]\n",
      "(7521, 512, 2)\n",
      "Wall time: 18.1 s\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "%%time\r\n",
    "val_inputs = tokenizer(dev_text, max_length=max_length, padding='max_length', truncation=True, return_tensors='tf') \r\n",
    "val_input_ids, val_attention_mask = val_inputs['input_ids'], val_inputs['attention_mask']"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 1.29 s\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "ix = 1178\r\n",
    "text = train_data.loc[ix,'text']\r\n",
    "print(len(text), text)\r\n",
    "sub = train_data.loc[ix,'spo_list'][0]['subject']\r\n",
    "obj = train_data.loc[ix,'spo_list'][0]['object']\r\n",
    "print(sub, obj)\r\n",
    "max_length = 256\r\n",
    "s_ids = tokenizer.encode(sub, max_length=max_length, truncation=True)[1:-1]\r\n",
    "o_ids = tokenizer.encode(obj, max_length=max_length, truncation=True)[1:-1]\r\n",
    "text_ids = tokenizer.encode(text, max_length=max_length, padding='max_length', truncation=True)\r\n",
    "print(text_ids)\r\n",
    "print(s_ids)\r\n",
    "print(o_ids)\r\n",
    "find_head_idx(s_ids, text_ids), find_head_idx(o_ids, text_ids)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "181 2009年12月，经重庆市国资委批准，重钢集团发起设立发行人前身重钢环保。重钢环保成立后，为优化管理架构、做大做强环保产业，将重钢环保打造为下属环保产业的投资、管理平台，重钢集团对其所属环保产业进行了重组，将其所持有的重庆丰盛100%的股权、三峰科技60%的股权、三峰卡万塔60%的股权、成都九江51%的股权和重庆同兴9.9%的股权以股权增资的方式注入重钢环保。\n",
      "重钢集团 重钢环保\n",
      "[101, 8170, 2399, 8110, 3299, 8024, 5307, 7028, 2412, 2356, 1744, 6598, 1999, 2821, 1114, 8024, 7028, 7167, 7415, 1730, 1355, 6629, 6392, 4989, 1355, 6121, 782, 1184, 6716, 7028, 7167, 4384, 924, 511, 7028, 7167, 4384, 924, 2768, 4989, 1400, 8024, 711, 831, 1265, 5052, 4415, 3373, 3354, 510, 976, 1920, 976, 2487, 4384, 924, 772, 689, 8024, 2199, 7028, 7167, 4384, 924, 2802, 6863, 711, 678, 2247, 4384, 924, 772, 689, 4638, 2832, 6598, 510, 5052, 4415, 2398, 1378, 8024, 7028, 7167, 7415, 1730, 2190, 1071, 2792, 2247, 4384, 924, 772, 689, 6822, 6121, 749, 7028, 5299, 8024, 2199, 1071, 2792, 2898, 3300, 4638, 7028, 2412, 705, 4670, 8135, 110, 4638, 5500, 3326, 510, 676, 2292, 4906, 2825, 8183, 110, 4638, 5500, 3326, 510, 676, 2292, 1305, 674, 1849, 8183, 110, 4638, 5500, 3326, 510, 2768, 6963, 736, 3736, 8246, 110, 4638, 5500, 3326, 1469, 7028, 2412, 1398, 1069, 130, 119, 130, 110, 4638, 5500, 3326, 809, 5500, 3326, 1872, 6598, 4638, 3175, 2466, 3800, 1057, 7028, 7167, 4384, 924, 511, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[7028, 7167, 7415, 1730]\n",
      "[7028, 7167, 4384, 924]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(16, 29)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "## debug\r\n",
    "model_path = '../model_dirs/bert-base-chinese'  \r\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\r\n",
    "max_length = 128\r\n",
    "print(f\"text ---\\n {train_data.loc[47:100,'text']}\")\r\n",
    "inputs = tokenizer(train_data.loc[47:100,'text'].to_list(), max_length=max_length, padding='max_length', return_tensors='tf', truncation=True)\r\n",
    "print('inputs keys --\\n', inputs.keys())\r\n",
    "print(f\"input_ids --\\n {inputs['input_ids']}\")\r\n",
    "tokens = tokenizer.decode(inputs['input_ids'][0])\r\n",
    "print('tokens --\\n', tokens)\r\n",
    "print(f\"spo_list ------\\n {train_data.loc[47,'spo_list']}\")\r\n",
    "text_len = len(tokens)\r\n",
    "text_len\r\n",
    "bert_model = TFBertModel.from_pretrained(model_path, output_hidden_states=True)\r\n",
    "outputs = bert_model(inputs)\r\n",
    "last_hidden_state, pooler_output, hidden_states = outputs[:3]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "text ---\n",
      " 47      近年来，全球软件用户群体快速增长，据wearesocial和hootsuite联合发布的《d...\n",
      "3608    2014年6月9日，天鹅股份召开第三届董事会第二十一次会议，审议通过了《关于转让图木舒克市天...\n",
      "5045    宝应锦程村镇银行主营业务为银行业务。截至2016年12月31日，宝应锦程村镇银行总资产为56...\n",
      "2499    公司2020年度、2019年度、2018年度的非经常性损益净额分别为1,237.73万元、1...\n",
      "7074    殷奇先生，39岁，本科，工程师，一级项目经理。1984年在上海城建学院参加工作，1995年到...\n",
      "                              ...                        \n",
      "1856    黄军林先生，汉族，1974年出生，中国国籍，无境外永久居留权。东南大学学士。曾就职于上海长江...\n",
      "7432    除因邵毅平辞任独立董事于2015年8月28日股东大会选举杨鹰彪为公司独立董事、因胡雄辞任监事...\n",
      "380     公司成立于1996年11月，设立时名称为海宁市马桥华生经编针织厂；华生针织厂于2005年5月...\n",
      "7148    资产总额逐年增长。2013年末、2014年末、2015年末及2016年6月末，公司资产总额分...\n",
      "100         最近三年，公司公允价值变动收益分别为77.36万元、-89.08万元及-109.08万元，\n",
      "Name: text, Length: 3554, dtype: object\n",
      "inputs keys --\n",
      " dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
      "input_ids --\n",
      " [[ 101 6818 2399 ...    0    0    0]\n",
      " [ 101 8127 2399 ...    0    0    0]\n",
      " [ 101 2140 2418 ...    0    0    0]\n",
      " ...\n",
      " [ 101 1062 1385 ...    0    0    0]\n",
      " [ 101 6598  772 ... 5763 5709  102]\n",
      " [ 101 3297 6818 ...    0    0    0]]\n",
      "tokens --\n",
      " [CLS] 近 年 来 ， 全 球 软 件 用 户 群 体 快 速 增 长 ， 据 wearesocial 和 hootsuite 联 合 发 布 的 《 digital2019 》 显 示 ， 当 前 全 球 网 民 数 量 达 43. 9 亿 人 ， 渗 透 率 达 57 % ， 网 民 数 量 的 增 长 将 带 动 pdf 等 通 用 软 件 的 市 场 需 求 ， 具 有 广 阔 的 市 场 空 间 。 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "spo_list ------\n",
      " [{'predicate': '关联方', 'object': 'hootsuite', 'subject': 'wearesocia', 'object_type': '公司', 'subject_type': '公司', 'object_index': {'begin': 30, 'end': 39}, 'subject_index': {'begin': 18, 'end': 28}}]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some layers from the model checkpoint at ../model_dirs/bert-base-chinese were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at ../model_dirs/bert-base-chinese.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[3554,128,768] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Tile]",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-77de7b6917e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mtext_len\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mbert_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTFBertModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbert_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mlast_hidden_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpooler_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tfs\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1012\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1013\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tfs\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, training, **kwargs)\u001b[0m\n\u001b[0;32m    895\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"output_hidden_states\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    896\u001b[0m             \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"return_dict\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 897\u001b[1;33m             \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"training\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    898\u001b[0m         )\n\u001b[0;32m    899\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tfs\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1012\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1013\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tfs\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, training, **kwargs)\u001b[0m\n\u001b[0;32m    648\u001b[0m             \u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"token_type_ids\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    649\u001b[0m             \u001b[0minputs_embeds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"inputs_embeds\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 650\u001b[1;33m             \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"training\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    651\u001b[0m         )\n\u001b[0;32m    652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tfs\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1012\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1013\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tfs\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, input_ids, position_ids, token_type_ids, inputs_embeds, training)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[0mposition_embeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         \u001b[0mposition_embeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mposition_embeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmultiples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m         \u001b[0mtoken_type_embeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[0mfinal_embeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposition_embeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken_type_embeds\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tfs\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mtile\u001b[1;34m(input, multiples, name)\u001b[0m\n\u001b[0;32m  11452\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  11453\u001b[0m       return tile_eager_fallback(\n\u001b[1;32m> 11454\u001b[1;33m           input, multiples, name=name, ctx=_ctx)\n\u001b[0m\u001b[0;32m  11455\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  11456\u001b[0m       \u001b[1;32mpass\u001b[0m  \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tfs\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mtile_eager_fallback\u001b[1;34m(input, multiples, name, ctx)\u001b[0m\n\u001b[0;32m  11492\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"T\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_attr_T\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Tmultiples\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_attr_Tmultiples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  11493\u001b[0m   _result = _execute.execute(b\"Tile\", 1, inputs=_inputs_flat, attrs=_attrs,\n\u001b[1;32m> 11494\u001b[1;33m                              ctx=ctx, name=name)\n\u001b[0m\u001b[0;32m  11495\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  11496\u001b[0m     _execute.record_gradient(\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tfs\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[3554,128,768] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Tile]"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "hidden_states[-1].shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TensorShape([54, 128, 768])"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def extract_subject(output, subject_ids):\r\n",
    "    start = tf.gather(output, subject_ids[:,:1], batch_dims=1)\r\n",
    "    end = tf.gather(output, subject_ids[:,1:], batch_dims=1)\r\n",
    "    subject = tf.keras.layers.Concatenate(axis=2)([start, end])\r\n",
    "    return subject[:, 0]\r\n",
    "\r\n",
    "extract_subject(hidden_states[-1], tf.constant(train_subject_ids[:hidden_states[-1].shape[0]]))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(54, 1536), dtype=float32, numpy=\n",
       "array([[ 0.25873297,  0.49238703,  0.63826686, ...,  0.11304718,\n",
       "        -0.9661733 , -0.4333823 ],\n",
       "       [ 0.42852157, -0.17608842,  0.8069094 , ...,  1.4964044 ,\n",
       "        -0.49943933, -0.20207542],\n",
       "       [ 0.5664912 , -0.12230435,  0.19252312, ...,  0.5424045 ,\n",
       "         0.27006415,  0.08944741],\n",
       "       ...,\n",
       "       [ 0.46302688, -0.4424666 ,  0.5141795 , ...,  0.4153874 ,\n",
       "         0.5806328 ,  0.04473295],\n",
       "       [-0.11299253, -0.3138919 , -1.4666147 , ...,  0.36222684,\n",
       "         0.43323463,  0.29208207],\n",
       "       [ 0.6611088 ,  0.7782924 , -0.7245413 , ...,  0.38568816,\n",
       "         0.23528749,  0.6906782 ]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 170
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class LayerNormalization(tf.keras.layers.Layer):\r\n",
    "    \"\"\"(Conditional) Layer Normalization\r\n",
    "    hidden_*系列参数仅为有条件输入时(conditional=True)使用\r\n",
    "    \"\"\"\r\n",
    "    def __init__(\r\n",
    "        self,\r\n",
    "        center=True,\r\n",
    "        scale=True,\r\n",
    "        epsilon=None,\r\n",
    "        conditional=False,\r\n",
    "        hidden_units=None,\r\n",
    "        hidden_activation='linear',\r\n",
    "        hidden_initializer='glorot_uniform',\r\n",
    "        **kwargs):\r\n",
    "        super(LayerNormalization, self).__init__(**kwargs)\r\n",
    "        self.center = center\r\n",
    "        self.scale = scale\r\n",
    "        self.conditional = conditional\r\n",
    "        self.hidden_units = hidden_units\r\n",
    "        self.hidden_activation = tf.keras.activations.get(hidden_activation)\r\n",
    "        self.hidden_initializer = tf.keras.initializers.get(hidden_initializer)\r\n",
    "        self.epsilon = epsilon or 1e-12\r\n",
    "        \r\n",
    "    def compute_mask(self, inputs, mask=None):\r\n",
    "        if self.conditional:\r\n",
    "            masks = mask if mask is not None else []\r\n",
    "            masks = [m[None] for m in masks if m is not None]\r\n",
    "            if len(masks) == 0:\r\n",
    "                return None\r\n",
    "            else:\r\n",
    "                return K.all(K.concatenate(masks, axis=0), axis=0)\r\n",
    "        else:\r\n",
    "            return mask\r\n",
    "        \r\n",
    "    def build(self, input_shape):\r\n",
    "        super(LayerNormalization, self).build(input_shape)\r\n",
    "        if self.conditional:\r\n",
    "            shape = (input_shape[0][-1],)\r\n",
    "        else:\r\n",
    "            shape = (input_shape[-1],)\r\n",
    "        if self.center:\r\n",
    "            self.beta = self.add_weight(\r\n",
    "                shape=shape, initializer='zeros', name='beta')\r\n",
    "        if self.scale:\r\n",
    "            self.gamma = self.add_weight(\r\n",
    "                shape=shape, initializer='ones', name='gamma')\r\n",
    "        if self.conditional:\r\n",
    "            if self.hidden_units is not None:\r\n",
    "                self.hidden_dense = tf.keras.layers.Dense(\r\n",
    "                    units=self.hidden_units,\r\n",
    "                    activation=self.hidden_activation,\r\n",
    "                    use_bias=False,\r\n",
    "                    kernel_initializer=self.hidden_initializer)\r\n",
    "            if self.center:\r\n",
    "                self.beta_dense = tf.keras.layers.Dense(\r\n",
    "                    units=shape[0], use_bias=False, kernel_initializer='zeros')\r\n",
    "            if self.scale:\r\n",
    "                self.gamma_dense = tf.keras.layers.Dense(\r\n",
    "                    units=shape[0], use_bias=False, kernel_initializer='zeros')\r\n",
    "\r\n",
    "    def call(self, inputs):\r\n",
    "        \"\"\"如果是条件Layer Norm，则默认以list为输入，第二个是condition\r\n",
    "        \"\"\"\r\n",
    "        if self.conditional:\r\n",
    "            inputs, cond = inputs\r\n",
    "            if self.hidden_units is not None:\r\n",
    "                cond = self.hidden_dense(cond)\r\n",
    "            for _ in range(K.ndim(inputs) - K.ndim(cond)):\r\n",
    "                cond = K.expand_dims(cond, 1)\r\n",
    "            if self.center:\r\n",
    "                beta = self.beta_dense(cond) + self.beta\r\n",
    "            if self.scale:\r\n",
    "                gamma = self.gamma_dense(cond) + self.gamma\r\n",
    "        else:\r\n",
    "            if self.center:\r\n",
    "                beta = self.beta\r\n",
    "            if self.scale:\r\n",
    "                gamma = self.gamma\r\n",
    "        outputs = inputs\r\n",
    "        if self.center:\r\n",
    "            mean = K.mean(outputs, axis=-1, keepdims=True)\r\n",
    "            outputs = outputs - mean\r\n",
    "        if self.scale:\r\n",
    "            variance = K.mean(K.square(outputs), axis=-1, keepdims=True)\r\n",
    "            std = K.sqrt(variance + self.epsilon)\r\n",
    "            outputs = outputs / std\r\n",
    "            outputs = outputs * gamma\r\n",
    "        if self.center:\r\n",
    "            outputs = outputs + beta\r\n",
    "        return outputs        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "def E2EModel(pretrained_path, max_length, p2id):\r\n",
    "    input_ids = tf.keras.layers.Input((max_length,), dtype=tf.int32, name='input_ids')\r\n",
    "    token_type_ids = tf.keras.layers.Input((max_length,), dtype=tf.int32, name='total_segment_ids')\r\n",
    "    attention_mask = tf.keras.layers.Input((max_length,), dtype=tf.int32, name='attention_mask')\r\n",
    "    subject_ids = tf.keras.layers.Input((2,), dtype=tf.int32, name='subject_ids')\r\n",
    "\r\n",
    "    bert_model = TFBertModel.from_pretrained(pretrained_path, output_hidden_states=True)\r\n",
    "    outputs = bert_model(input_ids=input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask)\r\n",
    "    last_hidden_state, pooler_output, hidden_states = outputs[:3]\r\n",
    "    layer_1 = hidden_states[-1]\r\n",
    "    \r\n",
    "    subject_preds = tf.keras.layers.Dense(units=2, activation='sigmoid',)(layer_1)\r\n",
    "    subject_preds = tf.keras.layers.Lambda(lambda x: x**2)(subject_preds)\r\n",
    "    subject_model = tf.keras.models.Model(inputs=[input_ids, token_type_ids, attention_mask], outputs=subject_preds)\r\n",
    "\r\n",
    "    subject = extract_subject([layer_1, subject_ids])\r\n",
    "    Normalization_1 = LayerNormalization(conditional=True)([layer_1, subject])\r\n",
    "    output = tf.keras.layers.Dense(units=len(p2id) * 2, activation='sigmoid' )(outputs)\r\n",
    "    output = tf.keras.layers.Lambda(lambda x: x**4)(output)\r\n",
    "    object_preds = tf.reshape((-1, len(p2id), 2))(output)\r\n",
    "    object_model = tf.keras.models.Model(input=[input_ids, token_type_ids, attention_mask, subject_ids], outputs=object_preds)\r\n",
    "\r\n",
    "    train_model = tf.keras.models.Model(input=[input_ids, token_type_ids, attention_mask, subject_ids], outputs= [subject_preds, object_preds])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\r\n",
    "pid = os.getpid()\r\n",
    "!kill -9 $pid"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "'kill' �����ڲ����ⲿ���Ҳ���ǿ����еĳ���\n",
      "���������ļ���\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!nvidia-smi"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Thu Jun 24 11:41:14 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 466.27       Driver Version: 466.27       CUDA Version: 11.3     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   39C    P8    N/A /  N/A |    233MiB /  4096MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1288    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A      1356    C+G   ...4__8j3eq9eme6ctt\\IGCC.exe    N/A      |\n",
      "|    0   N/A  N/A      8248    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A     10808    C+G   ...8wekyb3d8bbwe\\Cortana.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee43b18bdf7c1a4ac65a12e5fa87ef7b96ed7d04836ac8559d1db4b30b000de"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('tfs': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}